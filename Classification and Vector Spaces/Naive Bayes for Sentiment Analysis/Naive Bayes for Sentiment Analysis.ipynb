{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de41a8f2",
   "metadata": {},
   "source": [
    "# Naive Bayes for Sentiment Analysis\n",
    "In this notebook, you will be using Naive Bayes for sentiment analysis on tweets. Given a tweet, you will decide if it has a positive sentiment or a negative one. Specifically you will: \n",
    "\n",
    "* Train a naive bayes model on a sentiment analysis task\n",
    "* Test using your model\n",
    "* Compute ratios of positive words to negative words\n",
    "* Do some error analysis\n",
    "* Predict on your own tweet\n",
    "\n",
    "You may already be familiar with Naive Bayes and its justification in terms of conditional probabilities and independence.\n",
    "* We used the ratio of probabilities between positive and negative sentiments.\n",
    "* This approach gives us simpler formulas for these 2-way classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cabd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some library\n",
    "\n",
    "from utils import process_tweet, lookup\n",
    "import pdb\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12183e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below code to see detail about process_tweet and lookup function\n",
    "# ?lookup\n",
    "# ?process_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce477ad7",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "If you are running this notebook in your local computer (or not have ever downloaded data), don't forget to download the twitter samples and stopwords from nltk.\n",
    "```\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b32d0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sets of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "# split the data into two pieces, one for training and one for testing (validation set)\n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg\n",
    "test_x = test_pos + test_neg\n",
    "\n",
    "# avoid assumptions about the length of all_positive_tweets\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f6f540",
   "metadata": {},
   "source": [
    "# 1. Process the Data\n",
    "\n",
    "For any machine learning project, once you've gathered the data, the first step is to process it to make useful inputs to your model.\n",
    "- **Remove noise**: You will first want to remove noise from your data -- that is, remove words that don't tell you much about the content. These include all common words like 'I, you, are, is, etc...' that would not give us enough information on the sentiment.\n",
    "- We'll also remove stock market tickers, retweet symbols, hyperlinks, and hashtags because they can not tell you a lot of information on the sentiment.\n",
    "- You also want to remove all the punctuation from a tweet. The reason for doing this is because we want to treat words with or without the punctuation as the same word, instead of treating \"happy\", \"happy?\", \"happy!\", \"happy,\" and \"happy.\" as different words.\n",
    "- Finally you want to use stemming to only keep track of one variation of each word. In other words, we'll treat \"motivation\", \"motivated\", and \"motivate\" similarly by grouping them within the same stem of \"motiv-\".\n",
    "\n",
    "We have given you the function `process_tweet()` that does this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03171f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'great', 'day', ':)', 'good', 'morn']\n"
     ]
    }
   ],
   "source": [
    "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
    "\n",
    "# print cleaned tweet\n",
    "print(process_tweet(custom_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7343a2",
   "metadata": {},
   "source": [
    "## Implementing your helper functions\n",
    "\n",
    "To help you train your naive bayes model, you will need to compute a dictionary where the keys are a tuple (word, label) and the values are the corresponding frequency.  Note that the labels we'll use here are 1 for positive and 0 for negative.\n",
    "\n",
    "You will also implement a lookup helper function that takes in the `freqs` dictionary, a word, and a label (1 or 0) and returns the number of times that word and label tuple appears in the collection of tweets.\n",
    "\n",
    "For example: given a list of tweets `[\"i am rather excited\", \"you are rather happy\"]` and the label 1, the function will return a dictionary that contains the following key-value pairs:\n",
    "\n",
    "{\n",
    "    (\"rather\", 1): 2,\n",
    "    (\"happi\", 1) : 1,\n",
    "    (\"excit\", 1) : 1\n",
    "}\n",
    "\n",
    "- Notice how for each word in the given string, the same label 1 is assigned to each word.\n",
    "- Notice how the words \"i\" and \"am\" are not saved, since it was removed by process_tweet because it is a stopword.\n",
    "- Notice how the word \"rather\" appears twice in the list of tweets, and so its count value is 2.\n",
    "\n",
    "#### Instructions\n",
    "Create a function `count_tweets` that takes a list of tweets as input, cleans all of them, and returns a dictionary.\n",
    "- The key in the dictionary is a tuple containing the stemmed word and its class label, e.g. (\"happi\",1).\n",
    "- The value the number of times this word appears in the given collection of tweets (an integer).\n",
    "\n",
    "#### Note: `count_tweets` is the same as `freqs` (in previous notebook), to help you if you learn this course on cousera, i won't rename the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb2502b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(result, tweets, ys):\n",
    "    '''\n",
    "    Input:\n",
    "        result: a dictionary that will be used to map each pair to its frequency\n",
    "        tweets: a list of tweets\n",
    "        ys: a list corresponding to the sentiment of each tweet (either 0 or 1)\n",
    "    Output:\n",
    "        result: a dictionary mapping each pair to its frequency\n",
    "    '''\n",
    "    \n",
    "    for y, tweet in zip(ys, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            # define key of dict\n",
    "            pair = (word, y)\n",
    "            \n",
    "            # If the key exists in the dictionary, increment to 1\n",
    "            if pair in result:\n",
    "                result[pair] += 1        \n",
    "            # else, if the key new, set equal to 1\n",
    "            else:\n",
    "                result[pair] = 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "870a6ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test count_tweets function\n",
    "result = {}\n",
    "tweets = ['i am happy', 'i am tricked', 'i am sad', 'i am tired', 'i am tired']\n",
    "ys = [1, 0, 0, 0, 0]\n",
    "count_tweets(result, tweets, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddcf53c",
   "metadata": {},
   "source": [
    "# 2. Train your model using Naive Bayes\n",
    "Naive bayes is an algorithm that could be used for sentiment analysis. It takes a short time to train and also has a short prediction time.\n",
    "\n",
    "#### So how do you train a Naive Bayes classifier?\n",
    "- The first part of training a naive bayes classifier is to identify the number of classes that you have.\n",
    "- You will create a probability for each class.\n",
    "$P(D_{pos})$ is the probability that the document is positive.\n",
    "$P(D_{neg})$ is the probability that the document is negative.\n",
    "Use the formulas as follows and store the values in a dictionary:\n",
    "\n",
    "$$P(D_{pos}) = \\frac{D_{pos}}{D}\\tag{1}$$\n",
    "\n",
    "$$P(D_{neg}) = \\frac{D_{neg}}{D}\\tag{2}$$\n",
    "\n",
    "Where $D$ is the total number of documents, or tweets in this case, $D_{pos}$ is the total number of positive tweets and $D_{neg}$ is the total number of negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b99df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
