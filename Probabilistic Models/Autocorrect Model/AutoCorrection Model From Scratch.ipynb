{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOBd8ZkneP1h"
   },
   "source": [
    "<a name='0'></a>\n",
    "# Overview\n",
    "\n",
    "You use autocorrect every day on your cell phone and computer. In this notebook, you will explore what really goes on behind the scenes. Of course, the model you are about to implement is not identical to the one used in your phone, but it is still quite good. \n",
    "\n",
    "You will learn how to: \n",
    "\n",
    "- Get a word count given a corpus\n",
    "- Get a word probability in the corpus \n",
    "- Manipulate strings \n",
    "- Filter strings \n",
    "- Implement Minimum edit distance to compare strings and to help find the optimal path for the edits. \n",
    "- Understand how dynamic programming works\n",
    "\n",
    "\n",
    "Similar systems are used everywhere. \n",
    "- For example, if you type in the word **\"I am lerningg\"**, chances are very high that you meant to write **\"learning\"**, as shown in **Figure 1**. \n",
    "![fishy](image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxCsZ7IMfHsh"
   },
   "source": [
    "<a name='0-1'></a>\n",
    "# Edit Distance\n",
    "\n",
    "You will implement models that correct words that are 1 and 2 edit distances away. \n",
    "- We say two words are n edit distance away from each other when we need n edits to change one word into another. \n",
    "\n",
    "An edit could consist of one of the following options: \n",
    "\n",
    "- Delete (remove a letter): ‘hat’ => ‘at, ha, ht’\n",
    "- Switch (swap 2 adjacent letters): ‘eta’ => ‘eat, tea,...’\n",
    "- Replace (change 1 letter to another): ‘jat’ => ‘hat, rat, cat, mat, ...’\n",
    "- Insert (add a letter): ‘te’ => ‘the, ten, ate, ...’\n",
    "\n",
    "You will be using the four methods above to implement an Auto-correct. \n",
    "- To do so, you will need to compute probabilities that a certain word is correct given an input. \n",
    "\n",
    "This auto-correct you are about to implement was first created by [Peter Norvig](https://en.wikipedia.org/wiki/Peter_Norvig) in 2007. \n",
    "- His [original article](https://norvig.com/spell-correct.html) may be a useful reference for your studying.\n",
    "\n",
    "The goal of our spell check model is to compute the following probability:\n",
    "\n",
    "$$P(c|w) = \\frac{P(w|c)\\times P(c)}{P(w)} \\tag{1}$$\n",
    "\n",
    "The equation above is [Bayes Rule](https://en.wikipedia.org/wiki/Bayes%27_theorem). \n",
    "- Equation 1 says that the probability of a word being correct $P(c|w) $is equal to the probability of having a certain word $w$, given that it is correct $P(w|c)$, multiplied by the probability of being correct in general $P(C)$ divided by the probability of that word $w$ appearing $P(w)$ in general.\n",
    "- To compute equation 1, you will first import a data set and then create all the probabilities that you need using that data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMh7Rb_sfxI2"
   },
   "source": [
    "# **Part 1: Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bwxyiKBnfaH7"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hJOH8w5VgpTD"
   },
   "outputs": [],
   "source": [
    "def process_data(file_name):\n",
    "  \"\"\"\n",
    "  Input:\n",
    "    A file which you want to process\n",
    "  Output: \n",
    "    words: a list containing all the words in the corpus (text file) with lower case\n",
    "  \"\"\"\n",
    "\n",
    "  words = []\n",
    "  with open(file_name) as f:\n",
    "    data = f.read()\n",
    "  words = re.findall(r'\\w+', data.lower())\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1622891020707,
     "user": {
      "displayName": "Anh Dang Quy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjc9oywxROujI5Y7HUJPeay-CsytQ-LfJr_OOSl=s64",
      "userId": "02485246420508664150"
     },
     "user_tz": -420
    },
    "id": "L-IydexbikI_",
    "outputId": "daa8b291-d7d7-456a-abb2-f51369bebb85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'adventures', 'of', 'sherlock', 'holmes']\n",
      "There are 27041 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Take data from path\n",
    "path = os.getcwd()\n",
    "file_name = path + '/big.txt'\n",
    "\n",
    "words = process_data(file_name)\n",
    "vocab = set(words)\n",
    "print(f\"The first ten words in the text are: \\n{words[0:10]}\")\n",
    "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1622891020708,
     "user": {
      "displayName": "Anh Dang Quy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjc9oywxROujI5Y7HUJPeay-CsytQ-LfJr_OOSl=s64",
      "userId": "02485246420508664150"
     },
     "user_tz": -420
    },
    "id": "7NziMO9fi447",
    "outputId": "196160e0-5380-43e6-84cf-eddec0c53ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27041 key values pairs\n",
      "10 most words in corpus are [('the', 56324), ('of', 29389), ('and', 23241), ('to', 17407), ('in', 15916), ('a', 14231), ('is', 7560), ('it', 6960), ('that', 6674), ('was', 6417)]\n",
      "The count for the word 'thee' is 56324\n"
     ]
    }
   ],
   "source": [
    "word_count_dict = Counter(words)\n",
    "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
    "print(f\"10 most words in corpus are {word_count_dict.most_common(10)}\")\n",
    "print(f\"The count for the word 'thee' is {word_count_dict.get('the',0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tCvv3ttlcbM"
   },
   "source": [
    "Another way to get a list all words in the corpus and a dict which counting number of appearance of a word\n",
    "\n",
    "\n",
    "```\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "word_count_dict = Counter(words(open(file_name).read()))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R55dcUL7nfXB"
   },
   "source": [
    "Given the dictionary of word counts, compute the probability that each word will appear if randomly selected from the corpus of words.\n",
    "\n",
    "$$P(w_i) = \\frac{C(w_i)}{M} \\tag{2}$$\n",
    "where \n",
    "\n",
    "$C(w_i)$ is the total number of times $w_i$ appears in the corpus.\n",
    "\n",
    "$M$ is the total number of words in the corpus.\n",
    "\n",
    "For example, the probability of the word 'am' in the sentence **'I am happy because I am learning'** is:\n",
    "\n",
    "$$P(am) = \\frac{C(w_i)}{M} = \\frac {2}{7} \\tag{3}.$$\n",
    "\n",
    "because the number of \"am\" is 2 and total words of sentence is 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5i4Zuw1-k1kS"
   },
   "outputs": [],
   "source": [
    "def get_probs(word_count_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    '''\n",
    "    probs = {}  # return this variable correctly\n",
    "    \n",
    "    M = sum(word_count_dict.values())\n",
    "    for key in word_count_dict.keys():\n",
    "        probs[key] = word_count_dict[key] / M\n",
    "        \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1622891020709,
     "user": {
      "displayName": "Anh Dang Quy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjc9oywxROujI5Y7HUJPeay-CsytQ-LfJr_OOSl=s64",
      "userId": "02485246420508664150"
     },
     "user_tz": -420
    },
    "id": "2Gzkf8tioL0T",
    "outputId": "87353ac7-189a-417c-ec06-15b0ec25fd48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of probs is 27041\n",
      "P('the') is 0.0787\n"
     ]
    }
   ],
   "source": [
    "probs = get_probs(word_count_dict)\n",
    "print(f\"Length of probs is {len(probs)}\")\n",
    "print(f\"P('the') is {probs['the']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2rQAkBhymm4"
   },
   "source": [
    "Another way to get probability of a word\n",
    "\n",
    "```\n",
    "def Prob(word, M=sum(word_count_dict.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return word_count_dict[word] / M\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YH8z0Mf_o9wO"
   },
   "source": [
    "<a name='2'></a>\n",
    "# **Part 2: String Manipulations**\n",
    "\n",
    "Now, that you have computed $P(w_i)$ for all the words in the corpus, you will write a few functions to manipulate strings so that you can edit the erroneous strings and return the right spellings of the words. In this section, you will implement four functions: \n",
    "\n",
    "* `delete_letter`: given a word, it returns all the possible strings that have **one character removed**. \n",
    "* `switch_letter`: given a word, it returns all the possible strings that have **two adjacent letters switched**.\n",
    "* `replace_letter`: given a word, it returns all the possible strings that have **one character replaced by another different letter**.\n",
    "* `insert_letter`: given a word, it returns all the possible strings that have an **additional character inserted**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "u9fRugHRo4Kr"
   },
   "outputs": [],
   "source": [
    "def edit_one_letter(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    \n",
    "    # L is left, R is right of the set in 'splits' list\n",
    "    # For example, splits = [('', 'anh'), ('a', 'nh'), ('an', 'h'), ('anh', '')] \n",
    "    # ('a', 'nh') is a set in above list and L is 'a', R is 'nh'\n",
    "    delete = [L + R[1:] for L, R in splits if R]\n",
    "    switch = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    replace = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "    insert = [L + c + R for L, R in splits for c in letters]\n",
    "\n",
    "    return set(delete + switch + replace + insert)\n",
    "\n",
    "def edit_two_letters(word):\n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return set(e2 for e1 in edit_one_letter(word) for e2 in edit_one_letter(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1622891020709,
     "user": {
      "displayName": "Anh Dang Quy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjc9oywxROujI5Y7HUJPeay-CsytQ-LfJr_OOSl=s64",
      "userId": "02485246420508664150"
     },
     "user_tz": -420
    },
    "id": "Kj1jwpD0ooY7",
    "outputId": "1cb28594-3f30-4732-e415-29706a9da341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings with edit distance of two: 2654\n",
      "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
      "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
      "The data type of the returned object should be a set <class 'set'>\n",
      "Number of strings that are 2 edit distances from 'at' is 7154\n"
     ]
    }
   ],
   "source": [
    "tmp_edit_two_set = edit_two_letters(\"a\")\n",
    "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
    "\n",
    "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
    "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
    "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
    "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
    "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5ZoOGpDtzt3"
   },
   "source": [
    "# **Part 3: Suggest spelling suggestions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1622891020710,
     "user": {
      "displayName": "Anh Dang Quy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjc9oywxROujI5Y7HUJPeay-CsytQ-LfJr_OOSl=s64",
      "userId": "02485246420508664150"
     },
     "user_tz": -420
    },
    "id": "gBd4TLYiy7RW",
    "outputId": "d6005cd3-8090-4f77-e07e-5ad7e0b65660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P('the') is 0.0787\n"
     ]
    }
   ],
   "source": [
    "def Prob(word, M=sum(word_count_dict.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return word_count_dict[word] / M\n",
    "\n",
    "print(f\"P('the') is {Prob('the'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1622893457359,
     "user": {
      "displayName": "Anh Dang Quy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjc9oywxROujI5Y7HUJPeay-CsytQ-LfJr_OOSl=s64",
      "userId": "02485246420508664150"
     },
     "user_tz": -420
    },
    "id": "dPuwBEu7xaMf",
    "outputId": "e23c011d-8e1b-4a5e-a34f-703761029e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'somthing' can be {'smoothing', 'something', 'soothing', 'scathing', 'nothing', 'loathing'}\n"
     ]
    }
   ],
   "source": [
    "def known(words):\n",
    "  \"The subset of 'words' that appear in the dictionary of word_count_dict\"\n",
    "  return set(w for w in words if w in word_count_dict)\n",
    "\n",
    "print(f\"'somthing' can be {known(edit_two_letters('somthing'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622893613427,
     "user": {
      "displayName": "Anh Dang Quy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjc9oywxROujI5Y7HUJPeay-CsytQ-LfJr_OOSl=s64",
      "userId": "02485246420508664150"
     },
     "user_tz": -420
    },
    "id": "mVKh80ZA0sRs",
    "outputId": "68dc0f05-b3fd-46dd-fe50-ddcfc1788a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'something', 'soothing'}\n"
     ]
    }
   ],
   "source": [
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edit_one_letter(word)) or known(edit_two_letters(word)) or [word])\n",
    "print(candidates('somthing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1622893934253,
     "user": {
      "displayName": "Anh Dang Quy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjc9oywxROujI5Y7HUJPeay-CsytQ-LfJr_OOSl=s64",
      "userId": "02485246420508664150"
     },
     "user_tz": -420
    },
    "id": "c8zfBqt6APCd",
    "outputId": "7f409e7b-becb-46e9-a2a7-1902755991c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dys :  {'dye', 'dy', 'days', 'des'}\n",
      "'dys' is changed 'days'\n",
      "\n",
      "korrectud :  {'corrected'}\n",
      "'kerrectud' is changed 'corrected'\n",
      "\n",
      "somthing :  {'something', 'soothing'}\n",
      "'somthing' is changed 'something'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def correction(word, verbose=True): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    if verbose: \n",
    "        print(word, \": \", candidates(word))\n",
    "    return max(candidates(word), key=Prob)\n",
    "\n",
    "print(f\"'dys' is changed '{correction('dys')}'\\n\")\n",
    "print(f\"'kerrectud' is changed '{correction('korrectud')}'\\n\")\n",
    "print(f\"'somthing' is changed '{correction('somthing')}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrCd9jv5pOa_"
   },
   "source": [
    "# **Part 4: Minimum Edit Distance**\n",
    "Now that you could implemented auto-correct, but how do you evaluate the similarity between two strings? For example: 'waht' and 'what'\n",
    "\n",
    "Also how do you efficiently find the shortest path to go from the word, 'waht' to the word 'what'?\n",
    "\n",
    "## Dynamic Programing\n",
    "What is *dynamic programing*? \n",
    "\n",
    "Dynamic Programming breaks a problem down into subproblems which can be combined to form the final solution. Here, given a string source[0..i] and a string target[0..j], we will compute all the combinations of substrings[i, j] and calculate their edit distance. To do this efficiently, we will use a table to maintain the previously computed substrings and use those to calculate larger substrings.\n",
    "\n",
    "You have to create a matrix and update each element in the matrix as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9EX543ZBDN3"
   },
   "source": [
    "$$\\text{Initialization}$$\n",
    "\n",
    "\\begin{align}\n",
    "D[0,0] &= 0 \\\\\n",
    "D[i,0] &= D[i-1,0] + del\\_cost(source[i]) \\tag{4}\\\\\n",
    "D[0,j] &= D[0,j-1] + ins\\_cost(target[j]) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\\text{Per Cell Operations}$$\n",
    "\\begin{align}\n",
    " \\\\\n",
    "D[i,j] =min\n",
    "\\begin{cases}\n",
    "D[i-1,j] + del\\_cost\\\\\n",
    "D[i,j-1] + ins\\_cost\\\\\n",
    "D[i-1,j-1] + \\left\\{\\begin{matrix}\n",
    "rep\\_cost; & if src[i]\\neq tar[j]\\\\\n",
    "0 ; & if src[i]=tar[j]\n",
    "\\end{matrix}\\right.\n",
    "\\end{cases}\n",
    "\\tag{5}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So converting the source word **play** to the target word **stay**, using an input cost of one, a delete cost of 1, and replace cost of 2 would give you the following table:\n",
    "<table style=\"width:20%\">\n",
    "\n",
    "  <tr>\n",
    "    <td> <b> </b>  </td>\n",
    "    <td> <b># </b>  </td>\n",
    "    <td> <b>s </b>  </td>\n",
    "    <td> <b>t </b> </td> \n",
    "    <td> <b>a </b> </td> \n",
    "    <td> <b>y </b> </td> \n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td> <b>  #  </b></td>\n",
    "    <td> 0</td> \n",
    "    <td> 1</td> \n",
    "    <td> 2</td> \n",
    "    <td> 3</td> \n",
    "    <td> 4</td> \n",
    " \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <b>  p  </b></td>\n",
    "    <td> 1</td> \n",
    " <td> 2</td> \n",
    "    <td> 3</td> \n",
    "    <td> 4</td> \n",
    "   <td> 5</td>\n",
    "  </tr>\n",
    "   \n",
    "  <tr>\n",
    "    <td> <b> l </b></td>\n",
    "    <td>2</td> \n",
    "    <td>3</td> \n",
    "    <td>4</td> \n",
    "    <td>5</td> \n",
    "    <td>6</td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td> <b> a </b></td>\n",
    "    <td>3</td> \n",
    "     <td>4</td> \n",
    "     <td>5</td> \n",
    "     <td>4</td>\n",
    "     <td>5</td> \n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td> <b> y </b></td>\n",
    "    <td>4</td> \n",
    "      <td>5</td> \n",
    "     <td>6</td> \n",
    "     <td>5</td>\n",
    "     <td>4</td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operations used in this algorithm are 'insert', 'delete', and 'replace'. These correspond to the functions that you defined earlier: insert_letter(), delete_letter() and replace_letter(). switch_letter() is not used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram below describes how to initialize the table. Each entry in D[i,j] represents the minimum cost of converting string source[0:i] to string target[0:j]. The first column is initialized to represent the cumulative cost of deleting the source characters to convert string \"EER\" to \"\". The first row is initialized to represent the cumulative cost of inserting the target characters to convert from \"\" to \"NEAR\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='EditDistInit4.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:1000px;height:400px;\"/> </div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the formula for $D[i,j]$ shown in the image is equivalent to:\n",
    "\n",
    "\\begin{align}\n",
    " \\\\\n",
    "D[i,j] =min\n",
    "\\begin{cases}\n",
    "D[i-1,j] + del\\_cost\\\\\n",
    "D[i,j-1] + ins\\_cost\\\\\n",
    "D[i-1,j-1] + \\left\\{\\begin{matrix}\n",
    "rep\\_cost; & if src[i]\\neq tar[j]\\\\\n",
    "0 ; & if src[i]=tar[j]\n",
    "\\end{matrix}\\right.\n",
    "\\end{cases}\n",
    "\\tag{5}\n",
    "\\end{align}\n",
    "\n",
    "The variable `sub_cost` (for substitution cost) is the same as `rep_cost`; replacement cost.  We will stick with the term \"replace\" whenever possible.\n",
    "\n",
    "Below are some examples of cells where replacement is used. This also shows the minimum path from the lower right final position where \"EER\" has been replaced by \"NEAR\" back to the start. This provides a starting point for the optional 'backtrace' algorithm below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='EditDistExample1.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:1200px;height:400px;\"/> Examples Distance Matrix</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
    "    '''\n",
    "    Input: \n",
    "        source: a string corresponding to the string you are starting with\n",
    "        target: a string corresponding to the string you want to end with\n",
    "        ins_cost: an integer setting the insert cost\n",
    "        del_cost: an integer setting the delete cost\n",
    "        rep_cost: an integer setting the replace cost\n",
    "    Output:\n",
    "        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances\n",
    "        med: the minimum edit distance (med) required to convert the source string to the target\n",
    "    '''\n",
    "    m = len(source)\n",
    "    n = len(target)\n",
    "    \n",
    "    # Initialize a matrix with zeros and dimensions (m+1, n+1)\n",
    "    D = np.zeros((m+1, n+1), dtype=int)\n",
    "    \n",
    "    # Initialize values of 0-th row and 0-th column (i=0, j=0)\n",
    "    for row in range(1, m+1):\n",
    "        D[row, 0] = D[row-1, 0] + del_cost\n",
    "        \n",
    "    for column in range(1, n+1):\n",
    "        D[0, column] = D[0, column-1] + ins_cost\n",
    "    \n",
    "    # Calculate D[row-th, column-th]\n",
    "    for row in range(1, m+1):\n",
    "        for column in range(1, n+1):\n",
    "            \n",
    "            # Intialize r_cost to the 'replace' cost that is passed into this function\n",
    "            r_cost = rep_cost\n",
    "            \n",
    "            # Update r_cost = 0 if element of source and target are the same\n",
    "            if source[row-1] == target[column-1]:\n",
    "                r_cost = 0\n",
    "                \n",
    "            # Update the cost at row, col based on previous entries in the cost matrix\n",
    "            # Refer to the equation calculate for D[i,j] (the minimum of three calculated costs)\n",
    "            D[row, column] = min(D[row-1, column] + del_cost, D[row, column-1] + ins_cost, D[row-1, column-1] + r_cost)\n",
    "    \n",
    "    med = D[m, n]\n",
    "    \n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  4 \n",
      "\n",
      "   #  s  t  a  y\n",
      "#  0  1  2  3  4\n",
      "p  1  2  3  4  5\n",
      "l  2  3  4  5  6\n",
      "a  3  4  5  4  5\n",
      "y  4  5  6  5  4\n"
     ]
    }
   ],
   "source": [
    "# Example 1 \n",
    "source =  'play'\n",
    "target = 'stay'\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \",min_edits, \"\\n\")\n",
    "idx = list('#' + source)\n",
    "cols = list('#' + target)\n",
    "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  3 \n",
      "\n",
      "   #  n  e  a  r\n",
      "#  0  1  2  3  4\n",
      "e  1  2  1  2  3\n",
      "e  2  3  2  3  4\n",
      "r  3  4  3  4  3\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "source =  'eer'\n",
    "target = 'near'\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \",min_edits, \"\\n\")\n",
    "idx = list(source)\n",
    "idx.insert(0, '#')\n",
    "cols = list(target)\n",
    "cols.insert(0, '#')\n",
    "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eer ere 2\n",
      "eer eer 0\n"
     ]
    }
   ],
   "source": [
    "source = \"eer\"\n",
    "targets = edit_one_letter(source) \n",
    "for word in targets:\n",
    "    _, min_edits = min_edit_distance(source, word, 1, 1, 1)  # set ins, del, sub costs all to one\n",
    "    if min_edits != 1: print(source, word, min_edits)\n",
    "#     print(source, word, min_edits)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP4TSJSEYfiVHRnkZ2sp7Er",
   "mount_file_id": "1L2JUadFrtzqL1zkxGZaEkawZH42ZUmDY",
   "name": "NLP_Guide_AutoCorrection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
